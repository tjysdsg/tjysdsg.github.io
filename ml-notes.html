<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Machine Learning Notes - Jiyang (Mark) Tang</title>
<meta name="description" content="Machine Learning review notes">


  <meta name="author" content="Jiyang (Mark) Tang">
  
  <meta property="article:author" content="Jiyang (Mark) Tang">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Jiyang (Mark) Tang">
<meta property="og:title" content="Machine Learning Notes">
<meta property="og:url" content="https://tjysdsg.github.io/ml-notes">


  <meta property="og:description" content="Machine Learning review notes">







  <meta property="article:published_time" content="2022-10-12T19:06:28-07:00">






<link rel="canonical" href="https://tjysdsg.github.io/ml-notes">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Jiyang (Mark) Tang",
      "url": "https://tjysdsg.github.io/",
      "sameAs": ["https://github.com/tjysdsg","https://www.linkedin.com/in/tjy/"]
    
  }
</script>







<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Jiyang (Mark) Tang Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



    <!-- Clicky -->
<script async src="//static.getclicky.com/101330324.js"></script>
<noscript><p><img alt="Clicky" width="1" height="1" src="//in.getclicky.com/101330324ns.gif"/></p></noscript>

<!-- mathjax -->
<script>
    MathJax = {
        tex: {
            inlineMath: [['$', '$'], ['\\(', '\\)']],
            displayMath: [['$$', '$$'], ['\\[', '\\]']],
            tags: 'ams'
        }
    };

</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<!-- favicon generated by https://realfavicongenerator.net -->
<link rel="apple-touch-icon" sizes="180x180" href="/assets/images/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/images/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/images/favicon-16x16.png">
<link rel="manifest" href="/assets/images/site.webmanifest">
<link rel="mask-icon" href="/assets/images/safari-pinned-tab.svg" color="#5bbad5">
<link rel="shortcut icon" href="/assets/images/favicon.ico">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="msapplication-config" content="/assets/images/browserconfig.xml">
<meta name="theme-color" content="#ffffff">


<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-WYHC5BDEPZ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-WYHC5BDEPZ');

</script>

  </head>

  <body class="layout--single wide">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/"><img src="/assets/images/apple-touch-icon.png" alt="Jiyang (Mark) Tang"></a>
        
        <a class="site-title" href="/">
          Jiyang (Mark) Tang
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/posts">Posts</a>
            </li><li class="masthead__menu-item">
              <a href="/">About</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  
    <div class="author__avatar">
      
        <img src="/assets/images/me.jpg" alt="Jiyang (Mark) Tang" itemprop="image">
      
    </div>
  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name">Jiyang (Mark) Tang</h3>
    
    
      <div class="author__bio" itemprop="description">
        <p>Software Research Scientist at Intel</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name">Hillsboro, OR, United States</span>
        </li>
      

      
        
          
            <li><a href="https://www.linkedin.com/in/tjy" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin-in" aria-hidden="true"></i><span class="label">LinkedIn</span></a></li>
          
        
          
            <li><a href="https://github.com/tjysdsg" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
      

      

      
        <li>
          <a href="mailto:jiyang.mark.tang@gmail.com">
            <meta itemprop="email" content="jiyang.mark.tang@gmail.com" />
            <i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span>
          </a>
        </li>
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Machine Learning Notes">
    <meta itemprop="description" content="Machine Learning review notes">
    <meta itemprop="datePublished" content="2022-10-12T19:06:28-07:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">Machine Learning Notes
</h1>
          

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2022-10-12T19:06:28-07:00">October 12, 2022</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          6 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content" itemprop="text">
        
          <aside class="sidebar__right ">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4></header>
              <ul class="toc__menu"><li><a href="#fundamentals">Fundamentals</a><ul><li><a href="#overfittingunderfitting">Overfitting/Underfitting</a></li><li><a href="#prevent-underfitting">Prevent Underfitting?</a></li><li><a href="#prevent-overfitting">Prevent Overfitting?</a></li><li><a href="#biasvariance-trade-off">Bias/Variance Trade-Off</a></li><li><a href="#hypothesis-testing-on-ml-models">Hypothesis Testing on ML Models</a></li><li><a href="#logistic-regression">Logistic Regression</a><ul><li><a href="#sigmoid">Sigmoid</a></li><li><a href="#log-loss-logistic-losscross-entropy-loss">Log Loss (Logistic Loss/Cross-Entropy Loss)</a></li></ul></li></ul></li><li><a href="#regularization">Regularization</a><ul><li><a href="#l1-regularization-lasso-regression">L1 Regularization (Lasso Regression)</a></li><li><a href="#l2-regularization-ridge-regression">L2 Regularization (Ridge Regression)</a></li><li><a href="#priors-of-l1-and-l2">Priors of L1 and L2</a></li></ul></li><li><a href="#classic-machine-learning-models">Classic Machine Learning Models</a><ul><li><a href="#knn">KNN</a></li><li><a href="#k-means">k-means</a></li><li><a href="#bagging">Bagging</a></li><li><a href="#boosting">Boosting</a></li><li><a href="#stacking">Stacking</a></li><li><a href="#standardization-and-normalization">Standardization and Normalization</a></li><li><a href="#useful-links">Useful Links</a></li></ul></li></ul>

            </nav>
          </aside>
        
        <p>Machine Learning review notes</p>

<!--more-->

<h1 id="fundamentals">Fundamentals</h1>

<h2 id="overfittingunderfitting">Overfitting/Underfitting</h2>

<ul>
  <li>Overfitting = a model fits too well against its training data, and it cannot perform accurately against unseen data,
thus has high generalization error/out-of-sample error/risk</li>
  <li>Underfitting = a data model is unable to capture the relationship between the input and output variables accurately,
generating a high error rate on both the training set and unseen data</li>
</ul>

<h2 id="prevent-underfitting">Prevent Underfitting?</h2>

<ul>
  <li>Try a more complicated (non-linear, nn) model</li>
  <li>Decrease regularization</li>
  <li>Increase the duration of training</li>
  <li>Add in more features to provide more information</li>
</ul>

<h2 id="prevent-overfitting">Prevent Overfitting?</h2>

<ul>
  <li>Early stopping</li>
  <li>Cross validation</li>
  <li>Train with more data</li>
  <li>Data augmentation</li>
  <li>Feature selection</li>
  <li>Regularization</li>
  <li>Ensemble methods</li>
</ul>

<h2 id="biasvariance-trade-off">Bias/Variance Trade-Off</h2>

<ul>
  <li>$y$ labels</li>
  <li>We want to model function $f(x;D)$ , $f’(x)$ being my model, $x$ is the input, $D$ is the training data</li>
  <li>$y = f(x) = f’(x;D) + \varepsilon$ where $\varepsilon$ is the noise with $0$ mean and $\sigma^2$ variance</li>
</ul>

<p>We decompose its expected error on <strong>an unseen sample</strong> $x$:</p>

\[E_D \left[ (y - f'(x;D))^2 \right] = \left( \text{Bias}_D[f'(x;D)] \right)^2 + \text{Var}_D[f'(x;D)] + \sigma^2\]

<ul>
  <li>The bias term \(= E_D[f'(x;D)] - f(x)\)</li>
  <li>And the variance \(= E_D \left[ (E_D[f'(x;D)] - f'(x;D))^2 \right]\)</li>
</ul>

<p>The more complex the model is, the more data points it will capture, and the lower the bias will
be.
However, complexity will make the model “move” more to capture the data points, and hence its variance will be
larger.</p>

<ul>
  <li><strong>Underfitting = High bias, low variance</strong></li>
  <li><strong>Overfitting = Low bias, high variance</strong></li>
</ul>

<h2 id="hypothesis-testing-on-ml-models">Hypothesis Testing on ML Models</h2>

<p>Give a set of ground truths, model A, and model B, how do you be confident that one model is better than another?</p>

<ul>
  <li>$H_0$: Both models perform equally good</li>
  <li>$H_1$: Model B performs better</li>
</ul>

<p>Test model on various sets of data, calculate the mean $\mu$ and variance $\Sigma$ of the accuracy (or other metrics),
and perform significance testing (z-test, t-test, …).</p>

<p>The more test datasets the better according to the Central Limit Theorem.</p>

<h2 id="logistic-regression">Logistic Regression</h2>

<h3 id="sigmoid">Sigmoid</h3>

\[y = \frac{1}{1 + e{-z}}\]

<h3 id="log-loss-logistic-losscross-entropy-loss">Log Loss (Logistic Loss/Cross-Entropy Loss)</h3>

<p>Log Loss is the negative average of the log of corrected predicted probabilities for each instance.</p>

\[L(y, p) = - \frac{1}{N} \sum_{i}^{N} (y_i\log(p_i) + (1 - y_i)\log(1 - p_i))\]

<p>True label $y \in \{0, 1\}$ and probability estimate $p$</p>

<p><strong>Can’t use MSE loss</strong> because when using Sigmoid+MSE the loss function w.r.t. weights $ L(w) $ become non-convex.</p>

<h1 id="regularization">Regularization</h1>

<p>The intuitive difference between L1 and L2:
L1 tries to estimate the median of the data while L2 tries to estimate the mean of the data.</p>

<h2 id="l1-regularization-lasso-regression">L1 Regularization (Lasso Regression)</h2>

<ul>
  <li>Lasso = Least Absolute Shrinkage and Selection Operator</li>
  <li>L1 regularization leads to <strong>sparsity</strong> (some weight can be 0, so we can use it for <strong>feature selection</strong>)</li>
</ul>

\[L = \sum_i^N(y_i - \boldsymbol{\omega}^T \boldsymbol{x}_i)^2 + \lambda ||\boldsymbol{\omega_i}||_1\]

\[||\boldsymbol{\omega_i}||_1 = \sum_i^N |\boldsymbol{\omega}_i|\]

<h2 id="l2-regularization-ridge-regression">L2 Regularization (Ridge Regression)</h2>

<ul>
  <li>L2 regularization does not have sparsity (some weight can be close to 0 but not 0)</li>
</ul>

\[L = \sum_i^N(y_i - \boldsymbol{\omega}^T \boldsymbol{x}_i)^2 + \lambda ||\boldsymbol{\omega_i}||_2^2\]

\[||\boldsymbol{\omega_i}||_2^2 = \sum_i^N |\boldsymbol{\omega}_i|^2\]

<h2 id="priors-of-l1-and-l2">Priors of L1 and L2</h2>

<p>If we assume the prior of the weight $P(\omega)$ to be</p>

<ul>
  <li>a Laplace (Double Exponential) Distribution with mean 0, we can derive to Lasso Regression using MAP</li>
  <li>a Gaussian Distribution with mean 0, we can derive to Ridge Regression using MAP</li>
</ul>

<h1 id="classic-machine-learning-models">Classic Machine Learning Models</h1>

<h2 id="knn">KNN</h2>

<ul>
  <li>Classification and regression</li>
  <li>Non-parametric</li>
  <li>Algorithm:
    <ol>
      <li>Given a vector $v$, calculate the distance between it and every vector in the training data</li>
      <li>Sort the distances descendingly, keep the smallest $k$ samples</li>
      <li>For classification, the prediction of $v$ is the most common class labels in the $k$ neighbors. For regression,
the prediction is the mean value of the neighbors.</li>
    </ol>
  </li>
  <li>Applications: anomaly detection, search, recommender system</li>
</ul>

<h2 id="k-means">k-means</h2>

<ul>
  <li><strong>k-means is a NP-hard problem, the k-means algorithm usually refers to Loyd’s algorithm, a heuristic algorithm to
solve this problem</strong></li>
  <li>k-means partitions observations into $k$ clusters in which each observation belongs to the nearest cluster</li>
  <li>These heuristic algorithms <strong>don’t guarantee to find the global optimum</strong>. The result depend on the initial clusters</li>
  <li>Loyd’s algorithm (<em>the</em> k-means algorithm)
    <ol>
      <li>Determine $k$ and initialize $k$ clusters (determining the mean of each cluster $\mu_k$) in some way</li>
      <li>E-step: Compute the sum of the squared distances between each data point and all centroids, and assign each
data point to the closest cluster (centroid)</li>
      <li>M-step: Compute the new centroid (mean) by taking the average of the all data points that was assigned to
this cluster</li>
      <li>Keep iterating until the end condition is met (for example, max number of iterations finished)</li>
    </ol>
  </li>
  <li>k-means++ (better initialization)
    <ol>
      <li>Choose one data point as the initial center $c_1$ uniformly at random from the data samples</li>
      <li>For each data point $x$ not chosen, compute the distance $D(x)$ between it and the nearest center that has
already been chosen</li>
      <li>Choose one new data point at random as a new center, the probability of a point $x’$ being chosen is
$\frac{D(x)^2}{\sum_x D(x)^2}$</li>
      <li>Repeat until $k$ centers have been chosen</li>
      <li>Proceed to the standard k-means algorithm</li>
    </ol>
  </li>
  <li>Applications: Vector quantization for signal processing (where k-means was originally developed), cluster analysis,
feature learning, topic modeling</li>
</ul>

<h2 id="bagging">Bagging</h2>

<ul>
  <li>Bagging = bootstrap aggregating</li>
  <li>Designed to improve the stability and accuracy of ML algorithms. It reduces variance and helps to avoid overfitting</li>
  <li>Sample with replacement to create different data subsets (bootstraps), and train a model on each of these bootstraps
    <ul>
      <li>Sampling with replacement ensures each bootstrap is independent of its peers</li>
    </ul>
  </li>
  <li>The final prediction is the majority vote or average of all models’ predictions</li>
  <li>Bagging generally improves unstable methods, such as neural networks, classification and regression trees, and subset
selection in linear regression</li>
  <li>It can mildly degrade the performance of stable methods such as KNN</li>
  <li>Example: Random Forest</li>
</ul>

<h2 id="boosting">Boosting</h2>

<ul>
  <li>Boosting is a family of iterative ensemble algorithms that convert weak learners to strong ones</li>
  <li>Start by training the first weak classifier on the original dataset</li>
  <li>Samples are re-weighted based on how well the first classifier classifies them: misclassified samples are given higher
weight</li>
  <li>Train the second classifier on this re-weighted dataset. The ensemble now includes both classifiers</li>
  <li>Samples are re-weighted based on how well the ensemble classifies them.</li>
  <li>Repeat for as many iterations as needed. And the final strong classifier is created as a weighted combination of the
existing classifiers (classifiers with smaller training errors have higher weights)</li>
  <li>Example: Gradient-booted Tree (GBT)</li>
</ul>

<h2 id="stacking">Stacking</h2>

<ul>
  <li>Predictions from each model are stacked together and used as input to a final model (usually called a
meta-model)</li>
  <li>It’s similar to the weighted average of models, but the weights here are learned, rather than manually assigned</li>
  <li>There is a also a term called blending, which trains the meta model on a different holdout set, rather than on the
same training set used for the upstream models
    <ul>
      <li>Blending can prevent information leak but may lead to overfitting if the holdout set is small</li>
    </ul>
  </li>
</ul>

<h2 id="standardization-and-normalization">Standardization and Normalization</h2>

<ul>
  <li>Normalization or min-max scaling is calculate as</li>
</ul>

\[X' = \frac{X - X_{min}}{X_{max} - X_{min}}\]

<ul>
  <li>Standardization or z-score normalization is calculate as</li>
</ul>

\[X' = \frac{X - mean}{std}\]

<ul>
  <li>Normalization scales the range to [0, 1], while standardization is not bounded to a certain range.</li>
  <li>As normalization deals with min and max values, it can be affected by outliers easily</li>
  <li>If we don’t know the distribution of the data, normalization can often be useful.</li>
  <li>If we know the the distribution to be normal already, then standardization can be useful.</li>
</ul>

<h2 id="useful-links">Useful Links</h2>

<ul>
  <li>https://ekamperi.github.io/machine%20learning/2019/10/19/norms-in-machine-learning.html</li>
  <li>https://ekamperi.github.io/mathematics/2020/08/02/bayesian-connection-to-lasso-and-ridge-regression.html</li>
  <li>https://www.ibm.com/cloud/learn</li>
  <li>https://github.com/jayinai/nail-machine-learning/blob/main/concepts.md</li>
</ul>

        
      </section>

      <footer class="page__meta">
        
        


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2022-10-12T19:06:28-07:00">October 12, 2022</time></p>


      </footer>

      <section class="page__share">
  

  <a href="https://twitter.com/intent/tweet?text=Machine+Learning+Notes%20https%3A%2F%2Ftjysdsg.github.io%2Fml-notes" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Ftjysdsg.github.io%2Fml-notes" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3A%2F%2Ftjysdsg.github.io%2Fml-notes" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/libbacktrace" class="pagination--pager" title="C/C++: printing stacktrace containing file name, function name, and line numbers using libbacktrace
">Previous</a>
    
    
      <a href="#" class="pagination--pager disabled">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">You May Also Enjoy</h4>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/libbacktrace" rel="permalink">C/C++: printing stacktrace containing file name, function name, and line numbers using libbacktrace
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2021-07-27T06:44:00-07:00">July 27, 2021</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          2 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">I needed a library for printing stack traces when developing tan.
More specifically, the compiler and the runtime had to print the function names, source fil...</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/ctc" rel="permalink">Understanding the Math Behind CTC
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2021-06-17T19:56:00-07:00">June 17, 2021</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          6 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">In this post, I’m writing down my thought process of understanding the math behind 
Connectionist Temporal Classification (CTC) [1][2].

</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/mathjax-jekyll" rel="permalink">Adding mathjax to jekyll
</a>
      
    </h2>
    

  <p class="page__meta">
    
      
      <span class="page__meta-date">
        <i class="far fa-fw fa-calendar-alt" aria-hidden="true"></i>
        
        <time datetime="2021-05-29T00:31:00-07:00">May 29, 2021</time>
      </span>
    

    <span class="page__meta-sep"></span>

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-fw fa-clock" aria-hidden="true"></i>
        
          less than 1 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">Steps

1. Check for _includes/head.html file in your project

If you don’t have _includes/head.html in your jekyll project, create one.

Be careful that it w...</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>

    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2024 Jiyang (Mark) Tang. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>










  </body>
</html>
